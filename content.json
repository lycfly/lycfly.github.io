{"meta":{"title":"理想乡","subtitle":"LYC's Playgrand","description":"lyc's blog","author":"LYC","url":"http://yoursite.com"},"pages":[{"title":"about","date":"2018-12-16T12:19:10.000Z","updated":"2018-12-19T05:26:07.641Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"LYC"},{"title":"分类","date":"2018-12-18T16:28:01.000Z","updated":"2018-12-18T16:28:32.886Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-12-18T16:19:05.000Z","updated":"2018-12-18T16:24:25.887Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"机器学习——数据集划分法","slug":"机器学习——数据集划分法","date":"2019-01-11T09:16:57.000Z","updated":"2019-01-19T09:44:37.982Z","comments":true,"path":"2019/01/11/机器学习——数据集划分法/","link":"","permalink":"http://yoursite.com/2019/01/11/机器学习——数据集划分法/","excerpt":"机器学习——数据集划分法[TOC] ——周志华老师机器学习西瓜书的一些总结与备忘。","text":"机器学习——数据集划分法[TOC] ——周志华老师机器学习西瓜书的一些总结与备忘。 2.2训练与测试集的划分2.2.1留出法 (hold-out) 常见做法是将大约 $2/3、 4/5$ 的样本用于训练，剩余样本用于测试。 需要注意测试与训练的样本分布要尽量相同。 2.2.2 交叉验证法 (K-fold cross validation) 为减小 因样本划分不同而引入的差别 ， k 折交叉验证通常要随机使用不同的划分重复 p 次。最终的评估结果是这 p 次 k 折交叉验证结果的均值，例如常见的有10 次 10 折交叉验证。（实践中这么多折相当耗费计算能力，感觉不太会进行重复的k折取平均） 2.2.3留一法 (Leave-One-Out , LOO) 假定数据集 D 中包含 m 个样本 , 若令 k=m ， 则得到了交叉验证法的 一个特例。 留一法不受样本随机划分方式的影响。（每折只包含一个测试样本，与直接用D进行训练的结果相似） 感觉实际用途不大。。。先不说训练的时候往往是根据划分的交叉验证集上的测试结果来评定本次训练的优劣。因此验证集直接决定了每一折保存的是训练过程中的哪个模型。只留下一个样本作为交叉验证没有意义，除非有另外的测试集。如果是这种情况，还不如直接把所有数据都作为训练集。如果是为了使用K-fold融合多个模型提升效果，使用留一的方法过于极端，样本数量大时模型数量过多，样本较少时可以考虑。2.2.4 自助法 (bootstrapping) 但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集小，这必然会引入一些因训练样本规模不同而导致的估计偏差。 自助法在数据集较小、难以有效划分训练/测试集时很有用 此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处. 然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差. 参考《周志华机器学习西瓜书》第二章","categories":[{"name":"技术文","slug":"技术文","permalink":"http://yoursite.com/categories/技术文/"}],"tags":[{"name":"机器学习(ML)","slug":"机器学习-ML","permalink":"http://yoursite.com/tags/机器学习-ML/"}],"keywords":[{"name":"技术文","slug":"技术文","permalink":"http://yoursite.com/categories/技术文/"}]},{"title":"Tensorflow之Summary用法总结","slug":"Tensorflow之Summary用法总结","date":"2018-12-16T13:05:08.000Z","updated":"2018-12-19T05:26:32.000Z","comments":true,"path":"2018/12/16/Tensorflow之Summary用法总结/","link":"","permalink":"http://yoursite.com/2018/12/16/Tensorflow之Summary用法总结/","excerpt":"Tensorflow之Summary用法总结最近在研究tensorflow自带的例程speech_command,顺便学习tensorflow的一些基本用法。 其中tensorboard 作为一款可视化神器，可以说是学习tensorflow时模型训练以及参数可视化的法宝。 而在训练过程中，主要用到了tf.summary()的各类方法，能够保存训练过程以及参数分布图并在tensorboard显示。","text":"Tensorflow之Summary用法总结最近在研究tensorflow自带的例程speech_command,顺便学习tensorflow的一些基本用法。 其中tensorboard 作为一款可视化神器，可以说是学习tensorflow时模型训练以及参数可视化的法宝。 而在训练过程中，主要用到了tf.summary()的各类方法，能够保存训练过程以及参数分布图并在tensorboard显示。 tf.summary包含的诸多函数1、tf.summary.scalar用来显示标量信息，其格式为： 1tf.summary.scalar(tags, values, collections=None, name=None) 例如：tf.summary.scalar(‘mean’, mean) 一般在画loss,accuary时会用到这个函数。 2、tf.summary.histogram用来显示直方图信息，其格式为： 1tf.summary.histogram(tags, values, collections=None, name=None) 例如： tf.summary.histogram(‘histogram’, var) 一般用来显示训练过程中变量的分布情况 3、tf.summary.distribution分布图，一般用于显示weights分布 4、tf.summary.text可以将文本类型的数据转换为tensor写入summary中： 例如： 12text = \"\"\"/a/b/c\\\\_d/f\\\\_g\\\\_h\\\\_2017\"\"\"summary_op0 = tf.summary.text('text', tf.convert_to_tensor(text)) 5、tf.summary.image输出带图像的probuf，汇总数据的图像的的形式如下： ‘ tag /image/0’, ‘ tag /image/1’…，如：input/image/0等。 格式：tf.summary.image(tag, tensor, max_images=3, collections=None, name=Non 6、tf.summary.audio展示训练过程中记录的音频 7、tf.summary.merge_allmerge_all 可以将所有summary全部保存到磁盘，以便tensorboard显示。如果没有特殊要求，一般用这一句就可一显示训练时的各种信息了。 格式：tf.summaries.merge_all(key=’summaries’) 8、tf.summary.FileWriter指定一个文件用来保存图。 格式：tf.summary.FileWritter(path,sess.graph) 可以调用其add_summary（）方法将训练过程数据保存在filewriter指定的文件中 Tensorflow Summary 用法示例: 1234567tf.summary.scalar('accuracy',acc) #生成准确率标量图 merge_summary = tf.summary.merge_all() train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = &#123;...&#125;)#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 此时开启tensorborad： 1tensorboard --logdir=/summary_dir 便能看见accuracy曲线了。 另外，如果我不想保存所有定义的summary信息，也可以用tf.summary.merge方法有选择性地保存信息： 9、tf.summary.merge格式：tf.summary.merge(inputs, collections=None, name=None) 一般选择要保存的信息还需要用到tf.get_collection()函数 示例： 1234567tf.summary.scalar('accuracy',acc) #生成准确率标量图 merge_summary = tf.summary.merge([tf.get_collection(tf.GraphKeys.SUMMARIES,'accuracy'),...(其他要显示的信息)]) train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = &#123;...&#125;)#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 使用tf.get_collection函数筛选图中summary信息中的accuracy信息，这里的 tf.GraphKeys.SUMMARIES 是summary在collection中的标志。 当然，也可以直接： 12acc_summary = tf.summary.scalar('accuracy',acc) #生成准确率标量图 merge_summary = tf.summary.merge([acc_summary ,...(其他要显示的信息)]) #这里的[]不可省 如果要在tensorboard中画多个数据图，需定义多个tf.summary.FileWriter并重复上述过程。","categories":[{"name":"技术文","slug":"技术文","permalink":"http://yoursite.com/categories/技术文/"}],"tags":[{"name":"Tensorflow","slug":"Tensorflow","permalink":"http://yoursite.com/tags/Tensorflow/"}],"keywords":[{"name":"技术文","slug":"技术文","permalink":"http://yoursite.com/categories/技术文/"}]},{"title":"Ubuntu下QQ的使用并手动设置QQ文件保存路径","slug":"Ubuntu下QQ的使用并手动设置QQ文件保存路径","date":"2018-12-16T12:51:26.000Z","updated":"2018-12-19T05:25:44.003Z","comments":true,"path":"2018/12/16/Ubuntu下QQ的使用并手动设置QQ文件保存路径/","link":"","permalink":"http://yoursite.com/2018/12/16/Ubuntu下QQ的使用并手动设置QQ文件保存路径/","excerpt":"背景&amp;&amp;目标腾讯迟迟不肯做linux版本的QQ和微信，实在抠脚。没有办法，要在linux上使用QQ，目前我找到最好的办法就是使用wine，然而wine这个杀千刀的又是个坑货，QQ除了聊天，还有最重要的功能就是传文件啊Orz,这货不但把路径隐藏了，还藏得这么深，，，无奈只能一层一层找，在用软连接链接出来。。。","text":"背景&amp;&amp;目标腾讯迟迟不肯做linux版本的QQ和微信，实在抠脚。没有办法，要在linux上使用QQ，目前我找到最好的办法就是使用wine，然而wine这个杀千刀的又是个坑货，QQ除了聊天，还有最重要的功能就是传文件啊Orz,这货不但把路径隐藏了，还藏得这么深，，，无奈只能一层一层找，在用软连接链接出来。。。 下面主要以Ubuntu16.0.4为例，安装QQ,并手动设置文件保存路径。 ubuntu下使用wine安装QQ 主要参考 https://blog.csdn.net/hustcw98/article/details/79323024 下载地址：http://yun.tzmm.com.cn/index.php/s/XRbfi6aOIjv5gwj Appimage包不用做什么别的处理，安装啥的都不需要。。找到文件所在目录，终端中修改一下文件的权限 1chmod a+x QQ-20171129-x86_64.AppImage 之后就可以直接运行了。。。 1./QQ-20171129-x86_64.AppImage 然而作为深度windows依赖患者，自然不会习惯开个qq还要敲命令 索性在把它固定到开始栏： 首先把QQ-20171129-x86_64.AppImage 名字改的简单点，移动到linux下的/opt下： 先cd到QQ-20171129-x86_64.AppImage所在路径，之后 1sudo mv QQ-20171129-x86_64.AppImage /opt/QQ 再创建个启动器： 1sudo gedit /usr/share/applications/QQ.desktop 将以下内容复制进去： 1234567891011[Desktop Entry] Name=QQName[zh_CN]=QQExec=/opt/QQIcon=/opt/QQ.pngTerminal=falseX-MultipleArgs=falseType=ApplicationEncoding=UTF-8Categories=Application;StartupNotify=false 其中，QQ.png图标可以从网上随便找一个图标放到/opt或者随便什么路径，只要desktop里填写正确路径即可。 如此QQ就可以像windows里一样打开了，可能还要手动固定到任务栏，这个就不提了。 创建QQ文件保存路径这种方法安装的QQ实际是基于wine的。。。如果你在里面接收文件，想要找到路径，这货显示的是windows里一样的路径，还有什么还有“我的电脑”。。。linux里哪来这玩意 所以实际他把存的文件放在了一个隐藏文件夹里，在home/你的用户名 目录下按CTRL+h 显示隐藏文件，找到里面一个叫 1.QQ.unionfs 的文件夹，从QQ里接到的文件都放在 1.QQ.unionfs/drive_c/users/你的用户名/My Documents/Tencent Files 文件下了。 所以可以在自己在外面创建一个该文件夹的软连接，方便找文件： 1sudo ln -s /home/你的用户名/.QQ.unionfs/drive_c/users/你的用户名/My\\ Documents/Tencent\\ Files /home/你的用户名/ 大功告成！如此便可在linux下愉快的使用QQ了！","categories":[{"name":"技术文","slug":"技术文","permalink":"http://yoursite.com/categories/技术文/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}],"keywords":[{"name":"技术文","slug":"技术文","permalink":"http://yoursite.com/categories/技术文/"}]}]}